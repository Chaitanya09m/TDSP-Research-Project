# -*- coding: utf-8 -*-
"""Explorer TDSP - Chaitanya Mishra

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LI2fHssmgr04EioOyqF48-scJdovXb4d

# ðŸš— **Welcome to the <font color='crimson'>** **Explorer Transportation Data Science Project! ðŸš—**</font>
 Hosted by the [Northeast Big Data Innovation Hub](https://nebigdatahub.org/about) & [National Student Data Corps](https://nebigdatahub.org/nsdc), in collaboration with the [U.S. Department of Transportation Federal Highway Administration](https://highways.dot.gov/).


---

## <font color='crimson'>**Project Information and Background:**</font>

**Project Description:**

By participating in this project, you are joining a
community of transportation data science learners interested in making roads safer for vulnerable road users.

The Explorer TDSP has six Milestones, including guided transportation research into a community of interest. Each Milestone can take 1-5 hours, or less, depending on your level of experience.

To learn more about this project, including key highlights, incentives, and important links, [review the TDSP Webpage here](https://nebigdatahub.org/nsdc/tdsp/)!

## <font color='crimson'>**How to Get Started:**</font>

In order to work within this Google Colab Notebook, **please start by clicking on "File" in the top left corner of your notebook, and then "Save a copy in Drive." Rename the file to "Explorer TDSP - Your Full Name."** This will save a copy of the notebook in your personal Google Drive.

You may now begin!

---
---

## <font color='crimson'>**A Quick Introduction to Google Colab**</font>

Read below for a Google Colab QuickStart:
- Google Colab is a Python Notebook environment built by Google that's free for all.
- Colab Notebooks are made up of cells; cells can be either *text* or *code* cells. You can click the +code or +text button at the top of the Notebook to create a new cell.
- Text cells use a format called [Markdown](https://www.markdownguide.org/getting-started/). Knowledge of Markdown is not required for this project. However, if you'd like to learn more, [check out this Cheatsheet!](https://www.markdownguide.org/cheat-sheet/)
- Python code is executed in *code* cells. When you want to run your code, hover your cursor over the square brackets in the top left corner of your code cell. You'll notice a play button pop up! (â–¶) Click the play button to run the code in that cell. Code cells run one at a time.
- The memory shared across your notebook is called the *Runtime*. You can think of a Runtime as a "code session" where everything you create and execute is temporarily stored.
- Runtimes will persist for a short period of time, so you are safe if you need to refresh the page, but Google will shutdown a Runtime after enough time has passed. Everything that you have printed out will remain within your Notebook even if the runtime is disconnected.

If this is your first time using Google Colab, we highly recommend reviewing the [NSDC's *Using Google Colab Guide*](https://nebigdatahub.org/wp-content/uploads/2023/04/NSDC-Data-Science-Projects-Introduction-Using-Google-Colab.pdf) before continuing. For a more comprehensive guide, see [Colab's *Welcome To Colaboratory* walkthrough.](https://colab.research.google.com/github/prites18/NoteNote/blob/master/Welcome_To_Colaboratory.ipynb)

## <font color='crimson'>**An Introduction to Python Programming**</font>

Python is a programming language often used to analyze data.

Python is open-source, which means it's free to use and distribute, even for commercial purposes. Python's versatility allows it to be used for web development, data visualization, artificial intelligence, scientific computing, and more.

Python's extensive standard library, along with its powerful third-party packages, enable developers and data scientists to perform a vast array of tasks.

For those looking to dive deeper into Python, here are some valuable resources:
- [The Official Python Documentation](https://docs.python.org/3/) â€“ Offers comprehensive guides and reference materials for Python leaners.
- [Real Python](https://realpython.com/) â€“ Provides tutorials and articles for Python developers of all skill levels.
- [PyCon](https://pycon.org/) â€“ The largest annual gathering for the Python community, which is useful for learning from experts and discovering the latest developments in the Python ecosystem.
- [Python for Everybody](https://www.py4e.com/) â€“ A book and website by Dr. Charles Severance that offers a free course on Python for beginners.

**Let's review some essential Python Functions!**

Here are some key functions you'll frequently encounter:

1. **`head()`**: This function is crucial for getting a quick overview of your dataset. By default, it returns the first five rows, offering a snapshot of your data's structure and values.

2. **`describe()`**: This provides a summary of the statistical characteristics of your dataset. It's particularly useful for gaining insights into the distribution, mean, standard deviation, and range of numerical columns.

3. **`sum()`**: This calculates the total sum of a column or a series of numbers, proving essential for quick calculations and aggregations in data analysis.

4. **`isnull()`**: This helps identify missing or null values in your dataset, allowing for effective data cleaning and preprocessing.

5. **`value_counts()`**: Understanding the frequency of various values in your dataset is a common task in data science. The `value_counts()` function makes this easy by counting the occurrence of each unique value in a column.

Now that you've reviewed these important concepts, let's dive in to the project!

## <font color='crimson'>**Milestone #1 - Data Preparation**</font>
GOAL: The main goal of this milestone is to set up your environment, install the required packages, learn how to access data and do some basic exploratory data analysis.

**Step 1:** Setting up libraries and installing packages

A **library** is a collection of code that you can use in your programs, while a **package** is a folder that contains libraries or other packages, organized for easy use.

To install a library, we'll use the following format:
```python
 import <library name> as <shortname>
```
We use a *short name* since it is easier to refer to the package to access functions and also to refer to subpackages within the library. Think of it as a nickname for easier reference!
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import folium

"""These are the libraries that will help us throughout this project. We invite you to research each library for a better understanding.

We encourage you to read more about the important and most commonly used libraries like Pandas, Matplotlib, and Seaborn and write a few lines in your own words about what they do. [You may use the Data Science Resource Repository (DSRR) to find resources to get started!](https://nebigdatahub.org/nsdc/data-science-resource-repository/)

**TO DO:** Write a few lines about what each library does:




> * Pandas: Useful for data manipulation and analysis.It provides data structures like DataFrames and Series, which makes it easy to clean the data, transform, and analyze the data efficiently.
> * Matplotlib: Used for creating Visualization. Used to create graphs, bar plots etc.
> * Seaborn: Creats more detailed and informative visualizations. Helpful for creating visualizations for complex datasets.

**Step 2:** Letâ€™s access our data. We will be using the [NYC OpenData Motor Vehicle Collisions - Crashes dataset](https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95). According to NYC Open Data, "each row represents a crash event. The Motor Vehicle Collisions data tables contain information from all police reported motor vehicle collisions in NYC." If you need a reminder on how to upload your dataset, [please review helpful hints here.](https://nebigdatahub.org/wp-content/uploads/2023/04/NSDC-Data-Science-Projects-Introduction-Using-Google-Colab.pdf)

Since this is a large dataset, we highly recommend that you upload your data by [mounting your Google Drive](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=u22w3BFiOveA).

To mount your Google Drive, begin by finding the folder icon on the left side of your screen. When you click on this folder icon, you will open the Files window. Click on the icon at the top of the Files window that says "Mount Drive" as you hover over it.
"""

from google.colab import drive
drive.mount('/content/drive')

"""Next, we will read the data using the `pd.read_csv` function.
Ensure that you've downloaded the dataset from NYC OpenData, and uploaded the dataset to your Google Drive.

Hint: Your data's file path describes the location of where your data lives. To locate your data's file path, click on the folder/file-shaped icon on the left side of the Notebook. You'll notice a folder labeled "drive." Search for your Motor Vehicle Collisions Dataset within that folder. Right click on your Dataset to "copy path." Paste that path below.
"""

# TODO: Read the data using pandas read_csv function
data = pd.read_csv("/content/drive/MyDrive/Motor_Vehicle_Collisions_-_Crashes_20250106.csv")

"""**Step 3:** Let's see what the data looks like. We can use the `head` function which returns the first 5 rows of the dataset."""

# TODO: Print the first 5 rows of the data using head function of pandas
print(data.head())

# TODO: Describe the data using the describe function of pandas
desc_stats = data.describe()
desc_stats

"""The information above is currently formatted in scientific notation. Need a refresher? [Review how to analyze and convert to and from scientific notation here!](https://www.mathsisfun.com/numbers/scientific-notation.html)

1. Latitude & Longitude: The latitude and longitude indicate where the crashes are occurring. However, there are some data points with latitude and longitude values of 0, which is likely due to missing or inaccurate data.

2. Number of Persons Injured: On average, each crash has around 0.305 injuries. The maximum number of injuries in a single crash is 43.

3. Number of Persons Killed: Fatalities are rare, with an average of 0.00146 deaths per crash. The maximum number of deaths in one crash is 8.

4. Number of Pedestrians, Cyclists, and Motorists Injured/Killed: These columns provide a breakdown of the injuries and fatalities by type of individual involved.

5. Collision ID: This is a unique identifier for each crash.

---

##<font color='crimson'> **Milestone #2 - Data Ethics, Pre-Processing, and Exploration** </font>
GOAL: The main goal of this milestone is to assess the dataset, find missing values, and decide what to do with those missing data points.

**Step 1:**
Before we begin assessing our data for missing values, it is important that we understand the ethical implications surrounding data processing. To best prepare yourself for this module, review one or more of the following resources:
- [Data Science Ethics Flashcard Video Series](https://youtube.com/playlist?list=PLNs9ZO9jGtUB7XTjXy-ttoo2QSLld9SrV&feature=shared)
- [What Do I Need to Understand about Data Ethics?](https://www.youtube.com/watch?v=Efy8htCDueE)
-[Introduction to Data Cleaning](https://www.youtube.com/watch?v=t8WkoGLkdTk)

**TO DO:** Based on the resources above and outside knowledge, what are some potential bias issues related to the availability of data from well-resourced communities as compared to under-resourced communities? How might bias show up in our dataset?

> Potential Bias Issues in Data Availability
*   Unequal Reporting â€“ Well-resourced areas have better traffic cameras, digital systems, and emergency response, while under-resourced communities may have incomplete or missing crash reports.
*   Law Enforcement Differences â€“ Some areas may have more consistent police reporting, while others experience underreporting due to resource constraints or systemic bias.
*   Infrastructure Gaps â€“ Under-resourced areas may have poor street lighting and road conditions, leading to more crashes that go unreported or misclassified.

How Bias Might Show Up in Our Dataset
*   Skewed Crash Distribution â€“ If crashes in low-income areas arenâ€™t fully documented, it may seem like wealthier areas have more accidents, even if thatâ€™s not true.
*   Misleading Risk Assessments â€“ Missing data could lead to safety improvements in the wrong places, leaving high-risk areas overlooked.
*   Distorted Seasonal Trends â€“ Underreported nighttime crashes in poorly lit areas may cause an inaccurate understanding of seasonal risk factors.
*   Incomplete Data on Affected Communities â€“ Some neighborhoods or demographics may be underrepresented, leading to biased conclusions about crash frequency and severity.

**Step 2:**
Check the dataset for missing values.
"""

#TODO: Leverage the isnull() and sum() functions to find the number of missing values in each column
missing_values = data.isnull().sum()

#TODO: Turn the missing value counts into percentages
missing_values_percentage = ( missing_values / len(data)) * 100

#TODO: Return counts and percentages of missing values in each column
missing_data = pd.DataFrame({'Missing Values': missing_values, 'Percentage (%)': missing_values_percentage})
missing_data.sort_values(by='Percentage (%)', ascending=False)

"""Here's an overview of the missing values in the dataset:

Columns like VEHICLE TYPE CODE 5, CONTRIBUTING FACTOR VEHICLE 5, VEHICLE TYPE CODE 4, and so on have a high percentage of missing values. This is expected since not all crashes involve multiple vehicles or factors.

OFF STREET NAME and CROSS STREET NAME have significant missing values. This could be due to crashes occurring in locations where these details aren't applicable or weren't recorded.

ZIP CODE, BOROUGH, and ON STREET NAME also have missing values. This might be due to incomplete data entry or crashes occurring in areas where these specifics aren't easily determinable.

LOCATION, LATITUDE, and LONGITUDE have the same count of missing values, indicating that when one is missing, the others are likely missing as well.

**Step 3:** Create a bar chart to display the top 10 contributing factors (e.g. backing up unsafely, unsafe lane changing, etc.) to crashes within the dataset.
"""

#TODO: Plot a Bar Chart

top_factors = data['CONTRIBUTING FACTOR VEHICLE 1'].value_counts().head(10)


plt.figure(figsize=(12, 7))
# TODO: Plotting the top contributing factors, fill in x as the index field of the variable 'top_factors'
sns.barplot(x=top_factors.index, y=top_factors.values, palette="magma")
plt.title('Top 10 Contributing Factors to Crashes', fontsize=16)
plt.xlabel('Contributing Factors', fontsize=14)
plt.ylabel('Number of Crashes', fontsize=14)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""**TO DO:** Besides for "Unspecified," what are the top 3 contributing factors that cause the most crashes?

> *  Driver Inattention/Distraction
> *  Failure to Yield Right-of-Way
> *  Following Too Closely

**TO DO:** What recommendations would you make to new and current drivers after assessing the above data?

> *   Minimize Distractions : Avoid using mobile phones or attend a call while driving and try to cut of other things as well that might be cauing distraction while driving.
  
> *  Yield Right-of-Way, Use Turn Signals and be thorough with the Road & Traffic Rules :  Drivers should be aware of intersections, pedestrian crossings, and merging lanes and for that they should know all the sign and signals and what their meaning is. Use turn indicators correctly and aware of there surroundings while making a turn.

> *  Additionally, drivers must recognize the dangers of fatigue driving and driving hypnosis and take necessary breaks. Increased awareness through education and training programs can reinforce these safe driving habits and significantly reduce road accidents.

**Step 4:** Now, let's create another bar chart to determine which vehicle types were involved in the most crashes.
"""

# Determine the top vehicle types involved in crashes
top_vehicle_types = data['VEHICLE TYPE CODE 1'].value_counts().head(10)

# Plotting the top vehicle types
plt.figure(figsize=(12, 7))
sns.barplot(x=top_vehicle_types.index, y=top_vehicle_types.values, palette="cividis")
plt.title('Top 10 Vehicle Types Involved in Crashes', fontsize=16)
plt.xlabel('Vehicle Type', fontsize=14)
plt.ylabel('Number of Crashes', fontsize=14)
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability
plt.tight_layout()
plt.show()

"""**TO DO:** What are the top 3 vehicles that were most involved in crashes?


> *   Sedan
> *   Station Wagon/Sport Utility Vehicle
> *   Passenger Vehicle

**TO DO:** Why do you think that "Sedan[s]," "Station Wagon[s]," and "Passenger Vehicle[s]" are involved in a larger number of crashes, injuries, and deaths when compared to the rest of the vehicles? (Think outside the box!)

  These vehicles are among the most commonly owned and used for daily commuting, making them more prone to accidents. Following are the possible reasons:

> * Lack of Maintenance: Many drivers neglect regular servicing of these vehicles, leading to mechanical failures that can cause accidents.

> * Wildlife Hazards: The presence of deers and other wildlife that may suddenly cross roads especially on highways can contributes to unexpected collisions.

> * Driving Under the Influence (DUI): Some crashes may involve drivers under the influence of drugs or alcohol, affecting or impairing judgment and reaction time, increasing accident risks.

> * Parking Hazards & Unavailability: Limited or poorly designed parking spaces lead to illegal parking, sudden stops, double parking, and vehicles blocking visibility, increasing the risk of crashes.

> * Urban & Highway Traffic: Frequently driven in cities and highways with high traffic density, intersections, and pedestrian activity, these kind of vehicles have increasing crash risks.

> * Diverse Driver Demographics: Vehicles like sedans are operated by a wide range of drivers, including young and inexperienced individuals as well as senior citizens which is also one of the reasons for the crash.

> * Ride-Hailing & Taxis: Many sedans and station wagons are used in services like Uber and taxis, keeping them on the road for extended hours.

> * Used & Faulty Vehicles: A large number of people buy second-hand or faulty vehicle Sedan, Station Wagon, and Passenger Vehicle, often without realizing their high maintenance and use the cars whitout getting them fixed, can result in accidents.

**TO DO:** Review the x-axis of the bar chart you created above. </br>
1) What do you notice? </br>
2) What would you recommend we do to improve the bar chart, based on the x-axis (horizontal axis) and why? </br>
3) What recommendation would you make to those who are collecting and/or inputting data into this dataset?


> *  1)  Some names creates confusion, like Sedan and 4 dr Sedan, Taxi and TAXI.
> *  2) Make the categories more clear.
> *  3) Group similar vehicle types and use predefined categories when entering data.

**Step 5:**  A DataFrame is a two-dimensional and potentially heterogeneous tabular data structure with labeled axes (rows and columns). DataFrames allow for storing, manipulating, and retrieving data in a structured form, serving as the primary data structure for a multitude of data processing tasks. It is used with Python libraries like pandas.

Let's graph the *types* of crashes within this dataset and their frequencies. Begin by aggregating your data, convert to [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) for simple plotting, and plot.
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Aggregating data - Complete for Cyclist and Motorist
types_of_crashes = {
    'Pedestrian Injuries': data['NUMBER OF PEDESTRIANS INJURED'].sum(),
    'Cyclist Injuries': data['NUMBER OF CYCLIST INJURED'].sum(),
    'Motorist Injuries': data['NUMBER OF MOTORIST INJURED'].sum(),
    'Pedestrian Deaths': data['NUMBER OF PEDESTRIANS KILLED'].sum(),
    'Cyclist Deaths': data['NUMBER OF CYCLIST KILLED'].sum(),
    'Motorist Deaths': data['NUMBER OF MOTORIST KILLED'].sum()
}

# Converting to DataFrame for easier plotting - we want the items in the dictionary, use the items function
crash_types_df = pd.DataFrame(list(types_of_crashes.items()), columns=['Crash Type', 'Count'])


# Plot
plt.figure(figsize=(12, 7))
sns.barplot(x='Count', y='Crash Type', data=crash_types_df, palette="mako")
plt.title('Types of crashes and Their Frequencies')
plt.xlabel('Count')
plt.ylabel('Type of crash')
plt.tight_layout()
plt.show()

"""**TO DO:** Analyze the chart above. What is a recommendation you might make to the Department of Transportation based on this data?


> *  Improve Road Safety for Pedestrians & Cyclists

Expand protected bike lanes and pedestrian zones.
Enhance crosswalks, lighting, and signal timing for safer crossings.
> * Stricter Traffic Enforcement

Enforce distracted driving laws & speed limits.
Implement automated speed cameras in high-crash areas.
> * Traffic Signal & Infrastructure Upgrades

Adjust signal timing for safer pedestrian and cyclist movement.
Optimize street design to reduce accident-prone areas.
> * Public Awareness & Education

Launch safe driving & pedestrian awareness campaigns.
Educate cyclists and drivers on road-sharing rules.
> * Emergency Response Enhancements

Deploy faster medical response teams at high-risk zones.
Promote first-aid training for drivers to assist crash victims.

---

##<font color='crimson'> **Milestone #3 - Time Series Analysis**</font>
GOAL: The main goal of this milestone is to dive deeper into Time Series Analysis in order to better understand our data's trends over time.

**Step 1:**

Before we jump into Time Series Analysis (TSA), it's important to understand the basics, including Trends, Seasonality, and Residual Components.

Review one or more of the following resources and tell us what you learned about TSA!

*  [Learn about Time Series patterns here](https://otexts.com/fpp2/tspatterns.html)
* [Learn about Time Plots here](https://otexts.com/fpp2/time-plots.html)
*[Learn how to decompose Time Series Data into Trend and Seasonality](https://machinelearningmastery.com/decompose-time-series-data-trend-seasonality/)

**TO DO:** Write 3-5 sentences about TSA.
> Key Concepts in Time Series Analysis (TSA)  
- Trend â€“ Represents the long-term movement in the data, indicating whether values are increasing, decreasing, or remaining stable over time.  
- Seasonality â€“ Recurring patterns that happen at regular intervals, such as higher accident rates in winter due to icy roads.  
- Residual Components â€“ The random fluctuations that canâ€™t be explained by trends or seasonality, often considered noise in the data.  
- Time Series Decomposition â€“ Splitting data into trend, seasonality, and residual components helps in better understanding patterns and making accurate predictions.  
- Importance of TSA â€“ Helps identify underlying trends, detect anomalies, and make informed decisions based on historical data patterns.

**Step 2:** Let's begin by creating a chart that displays the average number of crashes per hour of the day. This will help us understand whether additional factors are contributing to crashes - i.e. rush hour, school dismissal time, night fall, etc.
"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Load the dataset
file_path = "/content/drive/MyDrive/Motor_Vehicle_Collisions_-_Crashes_20250106.csv"
data = pd.read_csv(file_path)

# Convert 'CRASH DATE' and 'CRASH TIME' to datetime
data['CRASH DATE'] = pd.to_datetime(data['CRASH DATE'])
data['CRASH TIME'] = pd.to_datetime(data['CRASH TIME'], format='%H:%M')

# Time of Day Analysis
data['Hour of Day'] = data['CRASH TIME'].dt.hour

# Group by 'Hour of Day' and calculate the average number of crashes per hour
average_crashes_per_hour = data.groupby('Hour of Day').size() / data['Hour of Day'].nunique()

# Plot the average number of crashes
plt.figure(figsize=(12, 6))
sns.barplot(x=average_crashes_per_hour.index, y=average_crashes_per_hour.values)
plt.title('Average Number of crashes per Hour of Day')
plt.xlabel('Hour of Day')
plt.ylabel('Average Number of crashes')
plt.xticks(range(0, 24))
plt.show()

"""**TO DO:** Which time of the day sees the most crashes? Why do you think so?

> *   3 PM - 6 PM (15:00 - 18:00), with a peak around at 4 PM - 5 PM (16:00 - 17:00).

> *   A large number of people leave work and schools. Increased pedestrian and cyclist activity, going on walks or back home leads to congested roads and chances of accidents increase. Also transition from daylight to dusk specially in winters occurs during this time period, reducing visibility and making driving conditions more challenging.

**Step 3:**
Plot a graph to determine how COVID-19 impacted the number of crashes per month, if at all.
"""

# Convert 'CRASH DATE' to datetime format
data['CRASH DATE'] = pd.to_datetime(data['CRASH DATE'])

# Group by month and year to get the number of crashes per month
monthly_crashes = data.groupby(data['CRASH DATE'].dt.to_period("M")).size()

# Plotting the trend over time
plt.figure(figsize=(15, 7))
monthly_crashes.plot()
plt.title('Number of Crashes per Month', fontsize=16)
plt.xlabel('Date', fontsize=14)
plt.ylabel('Number of Crashes', fontsize=14)
plt.tight_layout()
plt.show()

"""**TO DO:** What does your graph tell you about the impact of COVID-19 on the number of crashes per month? Why do you think this occurred?

> *  There is a sharp drop in the number of crashes. Also even after the covid years, the number of crashes have not yet returned to the pre-pandemic levels.
> * Reasons for this are:
1. Lockdowns & Stay-at-Home Orders
2. Remote/Work from home culture
3. School closures and shift to online classes
4. Reduced public gatherings
5. Travel restrictions
6. Stop on delivery services
7. No drunk driving cases

**Step 4**: Apply time series decomposition to review trends, seasonality, and residuals. New to time series analysis? Review the [Time Series Flashcard video series](https://youtube.com/playlist?list=PLNs9ZO9jGtUAqd0CNKySksPJJaOqYPMvk&feature=shared) here to learn about trends, components, and further analysis!
"""

import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.seasonal import seasonal_decompose

# Count the number of crashes per day, group by CRASH DATE
daily_crashes = data.groupby('CRASH DATE').size()

# Set plot style
sns.set(style="darkgrid")

# Plot the daily crashes time series
plt.figure(figsize=(15, 6))
plt.plot(daily_crashes.index, daily_crashes.values, label='Daily crashes')
plt.title('Daily Motor Vehicle Collisions in NYC')
plt.xlabel('Date')
plt.ylabel('Number of Crashes')
plt.legend()
plt.show()

# Decompose the time series
decomposition = seasonal_decompose(daily_crashes, model='additive', period=365)

# Plot the decomposed components
fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(15, 12))
decomposition.trend.plot(ax=ax1)
ax1.set_title('Trend')
decomposition.seasonal.plot(ax=ax2)
ax2.set_title('Seasonality')
decomposition.resid.plot(ax=ax3)
ax3.set_title('Residuals')
plt.tight_layout()
plt.show()

"""The visualizations above provide valuable insights into the time series of daily motor vehicle collisions in New York City:

1. Time Series Plot: This shows the number of daily crashes over time. You might observe long-term trends, seasonal patterns, or significant outliers.

2. Decomposed Components:
  
    2.1 Trend: This graph shows the long-term trend in the data, which can indicate whether crashes are increasing, decreasing, or stable over time.

    2.2 Seasonality: This reveals any regular patterns that repeat over a specific period, such as yearly. It helps identify times of the year with higher or lower crash frequencies.

    2.3 Residuals: These are the irregular components that cannot be attributed to the trend or seasonality. They might include random or unpredictable fluctuations.

**TO DO:** Based on your *trend graph*, are we seeing an increase or a decrease in crashes between 2014 and 2022?

> *  There is a increase in graph from 2014 to 2018-2019 but then there is a sharp decline starting from the mid of 2019 to 2021. And then crashes remain at a lower level than pre-pandemic years.


**TO DO:** Based on your *residual graph*, in what year(s) was there a significant unpredicted fluctuation? Why do you think so?

> *   occasional spikes in 2014-2019 can be seen. Significant fluctuations are seen around 2020 which coincides with the  COVID-19 pandemic.

---

##<font color='crimson'>**Milestone #4 - Geospatial Analysis**</font>
GOAL: The main goal of this milestone is to explore geospatial aspects of the dataset and get comfortable with regional analysis and geospatial visualizations.

**Step 1:** Before beginning this Milestone, we highly recommend that you review the [NSDC Geospatial Analysis Flashcard Video series](https://www.youtube.com/playlist?list=PLNs9ZO9jGtUAX_2g1-OJp8VkmVum6DqqP) if you are new to Geospatial Analysis!

Let's build a bar chart to compare and analyze the number of crashes across the five boroughs: Brooklyn (also known as Kings County), Queens, Manhattan, Bronx, and Staten Island.
"""

#TODO: Plot a bar chart to compare the number of crashes that occurred in each of the five boroughs.
# Set style
sns.set_style("whitegrid")

# Plotting the distribution of crashes by borough
plt.figure(figsize=(12, 7))
# Find the count of unique values of BOROUGHS. Hint: Use value_count function.
borough_count = data['BOROUGH'].value_counts()
sns.barplot(x=borough_count.index, y=borough_count.values, palette="viridis")
plt.title('Distribution of Crashes by Borough', fontsize=16)
plt.xlabel('Borough', fontsize=14)
plt.ylabel('Number of Crashes', fontsize=14)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""**TO DO:** Which borough has the highest number of crashes? Which borough has the lowest?

> * Highest: Brooklyn
> * Lowest: Staten Island


**TO DO:** Are there any reasons that you think a certain borough has a higher or lower number of crashes? What are some factors that may be causing this?

> *  Why do certain boroughs have higher or lower crash numbers?

Different Population Density, Traffic Flow intensity, Mixed Road Users, Frequent Construction & Road Work, all of these factors are some of the reasons why a certain boroughs have higher or lower crash numbers.

**Step 2:** Heatmaps are graphical representations that use color coding to represent different values and variables. Let's leverage a heatmap to determine the most dangerous intersections in the dataset. (**Note: the below cell may take a few minutes to run**)
"""

#TODO: Create a heatmap leveraging the latitude and longitude variables to determine where the most crashes are occurring
from folium.plugins import HeatMap

# Drop rows with missing latitude and longitude values
data_geo = data.dropna(subset=['LATITUDE', 'LONGITUDE'])

# Create a base map
m = folium.Map(location=[40.730610, -73.935242], zoom_start=10)  # Centered around NYC

# Create a heatmap
heat_data = [[row['LATITUDE'], row['LONGITUDE']] for index, row in data_geo.iterrows()]
HeatMap(heat_data, radius=8, max_zoom=13).add_to(m)

m.save("Heatmap.html")

"""**TO DO:** On the left side of your screen, you will see an icon that represents a folder or a file. Click on that icon to find the file titled "Heatmap.html". Click on the three dots next to your file and download your heatmap! Open the file once downloaded to see your creation.

When looking at your heatmap, where do you see a concentration of crashes?


> *  Manhattan (Midtown & Lower Manhattan)

> * Queens (Jamaica & Long Island City)

> * Bronx (South Bronx & Major Expressways)

> * Staten Island (Bridges & Major Roadways)

**Step 3:** Next, we will begin "Severity Mapping." We'll plot crashes on the map and code them based on severity, distinguishing between crashes that resulted in injuries and those that led to fatalities. This will give us a visual representation of where severe crashes tend to occur. </br>

You may initially want to code these incidents by using different colors, but it's important to think about your map and how accessible it is. Will a color-coded map be easy to read for everyone? Let's make a map that's inclusive for people with color blindness by also creating differently-shaped markers (squares, circles, and triangles) for crashes, injuries, and fatalities.
"""

#TODO: Continue building your heatmap
# Sample a subset of the data for visualization
sample_data_severity = data_geo.sample(n=1000, random_state=42)

# Create a base map
m_severity = folium.Map(location=[40.730610, -73.935242], zoom_start=10)

# Add crashes to the map with color coding and shape coding based on severity
for index, row in sample_data_severity.iterrows():
    if row['NUMBER OF PERSONS KILLED'] > 0:
        color = "Red"  # Fatalities

        folium.features.RegularPolygonMarker(
          location=[row['LATITUDE'], row['LONGITUDE']],
          number_of_sides=3,
          radius=5,
          gradient = False,
          color=color,
          fill=True,
          fill_color=color
        ).add_to(m_severity)


    elif row['NUMBER OF PERSONS INJURED'] > 0:
        color = "Purple"  # Injuries
        folium.CircleMarker(
          location=[row['LATITUDE'], row['LONGITUDE']],
          radius=5,
          color=color,
          fill=True,
          fill_color=color
       ).add_to(m_severity)
    else:
        color = "Gray"  # No injuries or fatalities
        folium.features.RegularPolygonMarker(
          location=[row['LATITUDE'], row['LONGITUDE']],
          number_of_sides=4,
          radius=5,
          gradient = False,
          color=color,
          fill=True,
          fill_color=color
        ).add_to(m_severity)


m_severity.save("severity.html")

"""**TO DO:** On the left side of your screen, you will see an icon that represents a folder or a file. Follow the same steps as above to download the "Severity.html" file.

**TO DO:** Which intersection(s) seem to be the most dangerous?

> * E 125th St & Lexington Ave (Harlem, Manhattan)

> * Grand Concourse & E 170th St (Bronx)


> * Atlantic Ave & Flatbush Ave (Brooklyn)


> * Queens Blvd & Roosevelt Ave (Queens)


> * Canal St & Bowery (Chinatown, Manhattan)

---
---

##<font color='crimson'>  **Milestone #5 - Self-Guided Research Question**</font>
GOAL: In this Milestone, you will be prompted to take what youâ€™ve learned throughout this project, build your own research question, and create a visualization(s) or model(s) to support your research goals.

You may create your visualization(s) in this Colab Notebook, or in Excel, Tableau, PowerBI, etc. Choose whichever medium you are most comfortable with! Be creative!

For participants who are comfortable with advanced data science techniques, we welcome you to leverage additional datasets, if desired. We highly recommend using pre-cleaned datasets from open data sources, like Kaggle.com.

If you have any questions or get stuck, please email nsdc@nebigdatahub.org with your queries. We're here to help!

**Step 1:** Review the dataset(s) that you will be using. As you explore, [consider the research question you want to answer](https://libraries.indiana.edu/sites/default/files/Develop_a_Research_Question.pdf)! Additionally, think about [who you are telling your data's story to](https://hbr.org/2013/04/how-to-tell-a-story-with-data). Your final audience may contain a group of transportation professionals, data scientists, peers, and the general public. Think about how would you frame your analysis differently for each of these groups.

**TO DO:** List one or more research questions here that you are considering.

> *  The Impact of Day-to-Night Transition on Crashes in NYC Across Seasons

**Step 2:** Now, think about what type of analysis you'd like to complete. Are you interested in looking at time series forecasting? Do you have additional maps in mind that you'd like to create? Is there a certain zip code or region you'd like to dive deeper into?

If you happen to be stuck, here are some examples that you can use or can guide you in choosing your research question!

**Examples:**
- How many crashes, injuries, and/or fatalies occurred in a zip code of interest?
- Which zip code sees the highest amount of crashes and what recommendations can you offer to help that community? Is it an underserved community?
- Do more crashes occur in underrepresented communities? Support your conclusion.
- Which day of the week sees the most crashes, injuries, and/or fatalities? (Hint: use the same method we used when we were analyzing the average number of crashes at different times of the day!)
- Does the geometric features of an intersection (90 degree intersection vs skewed intersection) affect the number of crashes that occur?

Be creative and think outside the box!

**Step 3:** Now that you've decided on your transportation research question, [explore the various types of visualizations you can create to support your research](https://datavizcatalogue.com/). You may create visualizations in this Google Colab notebook, Excel, R, SQL, PowerBI, Tableau, etc. Choose a program you are comfortable with!

You may also choose to build a model or leverage a different data science technique based on your experience level.

**Step 4:** Consider the **accessibility** of the graphs, charts, maps, or models you are interested in building. Use the tools below to learn more!
* How does your visualization appear to people [who may not be able to distinguish between muted colors or see your chart at all?](https://chartability.fizz.studio/)
*[Color Contrast Checker](https://policyviz.com/2022/11/01/color-contrast-checker-in-excel/)
*[SAS Graphics Accelerator](https://support.sas.com/software/products/graphics-accelerator/index.html)
*[TwoTone Data Sonification Tool](https://twotone.io/about/)
*[Making Visual Studio Accessible](https://code.visualstudio.com/docs/editor/accessibility)

To make visualizations more inclusive for people with color blindness, you can choose a color palette that is colorblind-friendly. `Seaborn`, a Python visualization library, provides several palettes that are designed to be perceptible by those with color vision deficiencies. Seaborn's `cubehelix` palette is a good choice, as it was designed specifically with color blindness in mind.

**Step 5:** Begin your research! Give yourself plenty of time to build your visualization or model. If you have any questions along the way, please email nsdc@nebigdatahub.org or write a message in the #[tdsp-community Slack Channel](https://join.slack.com/t/nsdcorps/shared_invite/zt-1h64t1e2p-La0AgU_HhymWUEGFQEcb3w).

**TO DO:** List the research question(s) you've chosen and why! Maybe you chose this question because it can help a community of interest or because it is similar to research you've completed in a class setting. Share your thoughts below.

> * How Does the Transition from Daylight to Nighttime Impact Crash Patterns Across Different Seasons in NYC?
Why This Research Question?
We chose this question because analyzing crash trends during the transition from daylight to night can provide critical insights for improving road safety in NYC. The transition period is when visibility drops, driver fatigue increases, and road conditions change, making it a high-risk time for accidents.

  This research is essential because of number of reasons:

- It can help urban planners and policymakers develop
targeted safety measures for high-risk hours.
- It aligns with real-world safety concerns faced by drivers, pedestrians, and cyclists.
- It contributes to seasonal traffic safety awareness, helping agencies plan safety interventions based on seasonal risks.
- Also It relates to previous project.

>* By exploring crash frequency, severity, weather impact, borough-wise distribution, and long-term trends, this study aims to provide actionable insights that can reduce transition-period crashes and improve nighttime road safety.

**TO DO:** Build a visualization, model, or use other statistical methods to gain insights into your data and to support your research question.
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import folium

from google.colab import drive

#  Read the data using pandas read_csv function
data = pd.read_csv("/content/drive/MyDrive/Motor_Vehicle_Collisions_-_Crashes_20250106.csv")
# Leverage the isnull() and sum() functions to find the number of missing values in each column
missing_values = data.isnull().sum()

# Turn the missing value counts into percentages
missing_values_percentage = ( missing_values / len(data)) * 100

# Return counts and percentages of missing values in each column
missing_data = pd.DataFrame({'Missing Values': missing_values, 'Percentage (%)': missing_values_percentage})
missing_data.sort_values(by='Percentage (%)', ascending=False)

# Begin creating here!
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


# Convert CRASH DATE and CRASH TIME to datetime format
data['CRASH DATE'] = pd.to_datetime(data['CRASH DATE'], errors='coerce')
data['CRASH TIME'] = pd.to_datetime(data['CRASH TIME'], format='%H:%M', errors='coerce').dt.hour

# Drop rows with missing values in important columns
data = data.dropna(subset=['CRASH DATE', 'CRASH TIME'])

# Extract year and month
data['Year'] = data['CRASH DATE'].dt.year
data['Month'] = data['CRASH DATE'].dt.month

# Assign Seasons and Sunset Time

sunset_times = {
    'Winter': 16.5,  # 4:30 PM
    'Spring': 19.5,  # 7:30 PM
    'Summer': 20.5,  # 8:30 PM
    'Fall': 17.0     # 5:00 PM
}

#  assign seasons
def get_season(month):
    if month in [12, 1, 2]:
        return 'Winter'
    elif month in [3, 4, 5]:
        return 'Spring'
    elif month in [6, 7, 8]:
        return 'Summer'
    else:
        return 'Fall'

# Assign season and sunset time to data
data['Season'] = data['Month'].apply(get_season)
data['Sunset Time'] = data['Season'].map(sunset_times)

# Creating a new column indicating whether crash happened before or after sunset
data['After Sunset'] = data['CRASH TIME'] >= data['Sunset Time']

# Analyze Crashes Before and After Sunset
crash_counts = data.groupby(['Season', 'After Sunset']).size().unstack()

# Plot crash counts
crash_counts.plot(kind='bar', figsize=(10, 6), stacked=True, colormap='coolwarm')
plt.title("Crashes Before and After Sunset by Season")
plt.xlabel("Season")
plt.ylabel("Number of Crashes")
plt.xticks(rotation=45)
plt.legend(["Before Sunset", "After Sunset"])
plt.grid(True)
plt.show()

"""Following deductions can be made from the above

1.   More crashes occur before sunset in all seasons, must be due to higher traffic volume during the daytime.

2.   Fall and Winter see a higher proportion of crashes after sunset, possibly due to shorter daylight hours and poorer driving conditions.

3. Summer has the lowest of nighttime crashes, must be due to longer daylight hours and better visibility.

4. Winter, despite having fewer total crashes, has a relatively higher share of nighttime crashes, must be due to slippery roads and early darkness.





"""

#Time-Series Analysis
crashes_per_year = data.groupby('Year').size()

# Plot time-series of crashes over the years
plt.figure(figsize=(12, 6))
plt.plot(crashes_per_year.index, crashes_per_year.values, marker='o', linestyle='-')
plt.title("Total Number of Crashes Per Year in NYC")
plt.xlabel("Year")
plt.ylabel("Number of Crashes")
plt.grid(True)
plt.show()

# Time-Series: Daytime Crashes per Year (Before Sunset)
daytime_crashes = data[data['After Sunset'] == False].groupby(['Year', 'Season']).size().unstack()

plt.figure(figsize=(12, 6))
daytime_crashes.plot(marker='o', linestyle='-')
plt.title("Daytime Crashes Per Year by Season")
plt.xlabel("Year")
plt.ylabel("Number of Crashes")
plt.legend(title="Season")
plt.grid(True)
plt.show()

#  Time-Series: Nighttime Crashes per Year (After Sunset)
night_crashes = data[data['After Sunset'] == True].groupby(['Year', 'Season']).size().unstack()

plt.figure(figsize=(12, 6))
night_crashes.plot(marker='o', linestyle='-')
plt.title("Nighttime Crashes Per Year by Season")
plt.xlabel("Year")
plt.ylabel("Number of Crashes")
plt.legend(title="Season")
plt.grid(True)
plt.show()

""">* Daytime Crashes Per Year by Season
Observations:

1. Summer has the highest number of daytime crashes every year (2012-2019).

2. Spring and Fall have similar trends, following Summer.Winter had the lowest number of daytime crashes (likely due to fewer people driving in extreme cold/weather conditions and shorter days).

Possible Explanations:

More daylight hours in summer â†’ More vehicles on the road â†’ Higher crashes. Spring and Fall see steady traffic, but Fall may have slightly higher crashes due to earlier sunsets. Winter crashes remain lower during the day, possibly due to fewer people driving in snow/ice conditions while the days being much shorter due to early sunset.

>* Nighttime Crashes Per Year by Season
Observations:

1. Fall had the highest number of nighttime crashes before 2020.
2. Winter nighttime crashes increased sharply from 2012-2019, then dropped significantly after 2020.
Summer and Spring have the lowest number of nighttime crashes across all years.

Possible Explanations:

Fall has the most nighttime crashes â†’ Earlier sunsets mean more time driving in darkness. Winter nighttime crashes are high because of poor visibility, slippery roads, and longer dark hours. Summer has fewer nighttime crashes â†’ Longer daylight hours reduce night driving risks.


"""

import scipy.stats as stats

# Group by season and sunset status
before_sunset = data[data['After Sunset'] == False].groupby('Season').size()
after_sunset = data[data['After Sunset'] == True].groupby('Season').size()

t_stat, p_value = stats.ttest_rel(before_sunset, after_sunset)

print(f"T-Statistic: {t_stat}")
print(f"P-Value: {p_value}")

if p_value < 0.05:
    print("There is a statistically significant difference in crash counts before and after sunset.")
else:
    print("No significant difference found in crash counts before and after sunset.")

# Summing up injuries and deaths before and after sunset
severity = data.groupby(['Season', 'After Sunset'])[['NUMBER OF PERSONS INJURED', 'NUMBER OF PERSONS KILLED']].sum()

# Visualizing the impact
severity.unstack().plot(kind='bar', figsize=(12,6), stacked=True, colormap="coolwarm")
plt.title("Crash Severity Before and After Sunset by Season")
plt.xlabel("Season")
plt.ylabel("Number of Injuries & Fatalities")
plt.legend(["Before Sunset - Injuries", "Before Sunset - Deaths", "After Sunset - Injuries", "After Sunset - Deaths"])
plt.grid(True)
plt.show()

"""Observations:

1. Crashes before sunset are more frequent in all seasons, but nighttime crashes are more severe.
2. Fall and Summer have the highest total crashes, while Winter has fewer but a higher share of nighttime crashes.
3. Nighttime crashes result in more fatalities, likely due to poor visibility, driver fatigue, and higher speeds.
4. Statistical analysis confirms a significant difference between crash counts before and after sunset.
"""

# Check available contributing factors
print(data['CONTRIBUTING FACTOR VEHICLE 1'].value_counts().head(20))

# Filter crashes caused by environmental conditions
weather_related = data[data['CONTRIBUTING FACTOR VEHICLE 1'].str.contains("Weather|Slippery|Fog|Rain", na=False, case=False)]

# Compare before and after sunset
weather_crashes = weather_related.groupby(['Season', 'After Sunset']).size().unstack()

# Plot
weather_crashes.plot(kind='bar', figsize=(10,6), stacked=True, colormap="plasma")
plt.title("Weather-Related Crashes Before and After Sunset by Season")
plt.xlabel("Season")
plt.ylabel("Number of Weather-Related Crashes")
plt.legend(["Before Sunset", "After Sunset"])
plt.grid(True)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Define crash severity categories
data['Crash Severity'] = 'Property Damage Only'  # Default category
data.loc[data['NUMBER OF PERSONS INJURED'] > 0, 'Crash Severity'] = 'Injury Crash'
data.loc[data['NUMBER OF PERSONS KILLED'] > 0, 'Crash Severity'] = 'Fatal Crash'

# Count of each type
severity_counts = data['Crash Severity'].value_counts()

# Plot the distribution
plt.figure(figsize=(8,6))
sns.barplot(x=severity_counts.index, y=severity_counts.values, palette="coolwarm")
plt.title("Crash Severity Distribution")
plt.xlabel("Type of Crash")
plt.ylabel("Number of Crashes")
plt.xticks(rotation=45)
plt.show()

"""Observations:
1. Most crashes are minor, and involve only property damage.
âœ… Injury-related crashes are fewer but still a concern.
âœ… Fatal crashes are rare, indicating that NYCâ€™s traffic safety measures are effective.
"""

# Count crashes by borough before and after sunset
borough_crashes = data.groupby(['BOROUGH', 'After Sunset']).size().unstack()

# Plot
borough_crashes.plot(kind='bar', figsize=(12,6), stacked=True, colormap="cividis")
plt.title("Crashes by Borough: Before vs. After Sunset")
plt.xlabel("Borough")
plt.ylabel("Number of Crashes")
plt.legend(["Before Sunset", "After Sunset"])
plt.grid(True)
plt.show()

"""Observations:
Nighttime crashes are more common in the Bronx and Queens.
Manhattan has fewer crashes must be due to lower vehicle speeds and better infrastructure.
Staten Island, being the least populated borough, has the lowest number of crashes overall.


"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Define transition time ranges for each season
transition_times = {
    'Winter': (16, 18),  # 4 PM - 6 PM
    'Spring': (18, 20),  # 6 PM - 8 PM
    'Summer': (19, 21),  # 7 PM - 9 PM
    'Fall': (17, 19)     # 5 PM - 7 PM
}

# Function to determine if a crash happened in the transition period of its season
def is_in_transition(row):
    start, end = transition_times[row['Season']]
    return start <= row['CRASH TIME'] < end

# Apply function to flag crashes occurring during transition hours
data['In Transition Period'] = data.apply(is_in_transition, axis=1)

# Count crashes in transition period per season
transition_crashes = data[data['In Transition Period']].groupby('Season').size()

# Plot the results
plt.figure(figsize=(10,6))
sns.barplot(x=transition_crashes.index, y=transition_crashes.values, palette="coolwarm")
plt.title("Number of Crashes During Transition Period Across Seasons")
plt.xlabel("Season")
plt.ylabel("Number of Crashes")
plt.grid(True)
plt.show()

"""Observations:
1. Crashes during daylight transition hours are highest in Fall and Winter due to earlier sunsets and difficult driving conditions.
2. Summer has the least daylight transition crashes, likely due to longer daylight hours and better visibility.
3. Spring sees more daylight transition crashes than Summer, possibly due to weather conditions.
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Define transition times for legend clarity
transition_labels = {
    'Winter': '4-6 PM',
    'Spring': '6-8 PM',
    'Summer': '7-9 PM',
    'Fall': '5-7 PM'
}

# Update legend labels with transition times
legend_labels = [f"{season} ({time})" for season, time in transition_labels.items()]

# Create figure
plt.figure(figsize=(12, 6))

# Plot the data
ax = comparison_df.plot(kind='bar', figsize=(12,6), colormap="coolwarm", edgecolor="black", width=0.8)

# Add title with transition periods
plt.title("Seasonal Comparison of Crashes During Transition Periods\n(Winter: 4-6 PM, Spring: 6-8 PM, Summer: 7-9 PM, Fall: 5-7 PM)",
          fontsize=14, fontweight='bold')

# Axis labels
plt.xlabel("Season (Crashes Recorded In)", fontsize=12)
plt.ylabel("Number of Crashes", fontsize=12)

# Rotate x-axis labels for readability
plt.xticks(rotation=0)

# Add grid lines for better readability
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Add value labels on bars
for p in ax.patches:
    ax.annotate(f'{int(p.get_height())}',
                (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='bottom', fontsize=10, fontweight='bold')

# Improve legend with transition times
plt.legend(legend_labels, title="Transition Period of", fontsize=10, title_fontsize=12, loc="upper right")

# Show plot
plt.show()

"""Observation:

1. Winterâ€™s Transition Period (4-6 PM) Has the Most Crashes Across All Seasons.
2. Fallâ€™s Transition Period (5-7 PM) Sees High Crashes in All Seasons
3. Spring and Summer Transition Periods (6-8 PM, 7-9 PM) Have Lower Crash Counts
4. Crashes in Fall and Winter are High Across All Transition Periods

These observations indicates that early evening hours are the most dangerous. Summer has the lowest crash counts during transition periods, likely due to longer daylight and better visibility. Even in other seasons, crashes remain high during Fall and Winterâ€™s transition periods, highlighting their overall higher risk. Crashes during the Summer transition period (7-9 PM) remain lower across all seasons, suggesting that later evening hours are generally safer.
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Define transition time ranges for each season
transition_times = {
    'Winter': (16, 18),  # 4 PM - 6 PM
    'Spring': (18, 20),  # 6 PM - 8 PM
    'Summer': (19, 21),  # 7 PM - 9 PM
    'Fall': (17, 19)     # 5 PM - 7 PM
}

# Identify crashes where weather is a contributing factor
weather_conditions = ["Rain", "Snow", "Fog", "Slippery"]
weather_crashes = data[data['CONTRIBUTING FACTOR VEHICLE 1'].str.contains('|'.join(weather_conditions), na=False, case=False)]

# Create a dictionary to store results
weather_impact_results = {}

# Iterate through each season's transition period and count weather-related crashes
for season, (start_hour, end_hour) in transition_times.items():
    # Filter crashes occurring in this season's transition period
    data[f'In {season} Transition'] = (data['CRASH TIME'] >= start_hour) & (data['CRASH TIME'] < end_hour)

    # Count weather-related crashes across all seasons during this transition period
    weather_impact_results[season] = weather_crashes[data[f'In {season} Transition']].groupby('Season').size()

# Convert results to a DataFrame for visualization
weather_comparison_df = pd.DataFrame(weather_impact_results).fillna(0)

# Plot the comparison of weather-related crashes
plt.figure(figsize=(12, 6))
weather_comparison_df.plot(kind='bar', figsize=(12,6), colormap="coolwarm", edgecolor="black", width=0.8)

# Add title with transition periods
plt.title("Weather-Related Crashes During Transition Periods Across Seasons\n(Winter: 4-6 PM, Spring: 6-8 PM, Summer: 7-9 PM, Fall: 5-7 PM)",
          fontsize=14, fontweight='bold')

# Axis labels
plt.xlabel("Season (Crashes Recorded In)", fontsize=12)
plt.ylabel("Number of Weather-Related Crashes", fontsize=12)

# Rotate x-axis labels for readability
plt.xticks(rotation=0)

# Add grid lines for better readability
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Add value labels on bars
ax = plt.gca()
for p in ax.patches:
    if p.get_height() > 0:  # Only label bars with values
        ax.annotate(f'{int(p.get_height())}',
                    (p.get_x() + p.get_width() / 2., p.get_height()),
                    ha='center', va='bottom', fontsize=10, fontweight='bold')

# Improve legend with transition times
plt.legend(title="Transition Period of", fontsize=10, title_fontsize=12, loc="upper right")

# Show plot
plt.show()

"""---

Key Observations
1. Winterâ€™s Transition Period (4-6 PM) Has the Most Weather-Related Crashes. Winter itself records the highest number of weather-related crashes during its own transition period.
Fall and Spring also show a high number of crashes in the Winter transition period.
This suggests that the time window of 4-6 PM is extremely dangerous for weather-related crashes, regardless of the season.
2. Summerâ€™s Transition Period (7-9 PM) Has the Least Weather-Related Crashes while Spring being the moderate.
"""

from folium.plugins import HeatMap
import folium

# Separate crashes before and after sunset
daytime_crashes = data[data['After Sunset'] == False].dropna(subset=['LATITUDE', 'LONGITUDE'])
nighttime_crashes = data[data['After Sunset'] == True].dropna(subset=['LATITUDE', 'LONGITUDE'])

# Create daytime heatmap
day_map = folium.Map(location=[40.730610, -73.935242], zoom_start=10)
HeatMap([[row['LATITUDE'], row['LONGITUDE']] for _, row in daytime_crashes.iterrows()], radius=8).add_to(day_map)
day_map.save("Daytime_Crashes_Heatmap.html")

# Create nighttime heatmap
night_map = folium.Map(location=[40.730610, -73.935242], zoom_start=10)
HeatMap([[row['LATITUDE'], row['LONGITUDE']] for _, row in nighttime_crashes.iterrows()], radius=8).add_to(night_map)
night_map.save("Nighttime_Crashes_Heatmap.html")

# Create seasonal heatmaps
for season, (start_hour, end_hour) in transition_times.items():
    transition_data = data[(data['CRASH TIME'] >= start_hour) & (data['CRASH TIME'] < end_hour)].dropna(subset=['LATITUDE', 'LONGITUDE'])

    season_map = folium.Map(location=[40.730610, -73.935242], zoom_start=10)
    HeatMap([[row['LATITUDE'], row['LONGITUDE']] for _, row in transition_data.iterrows()], radius=8).add_to(season_map)

    season_map.save(f"{season}_Transition_Crashes_Heatmap.html")

"""1. Winter Transition Period (4-6 PM): Crash hotspots are concentrated in high-traffic areas such as Manhattan, Brooklyn, and Queens.
Higher crash density in residential and commercial zones suggests that winter transition crashes mostly occur during evening commutes. More crashes in the Bronx and Queens compared to other seasons explains that boroughs with more highways might experience more winter-related transition crashes.

2. Spring Transition Period (6-8 PM): Crash hotspots are still present in Manhattan and Brooklyn but are slightly less dense than in winter.
More crashes occur in intersections rather than highways. Also more crashes near parks and residential zones (Prospect Park, Central Park, Flushing Meadows) â€“ indicating possible pedestrian involvement. Longer daylight helps visibility, but increased traffic in residential zones suggests more pedestrian-vehicle incidents.

3. Summer Transition Period (7-9 PM): Overall, fewer transition crashes compared to winter and fall.
Clusters remain in Manhattan and Brooklyn but are smaller in size. Extended daylight (sunset around 8:30 PM) reduces visibility-related crashes compared to winter.

4. Fall Transition Period (5-7 PM):
Crash density increases compared to spring and summer but remains lower than winter. Clusters reappear in Manhattan, Brooklyn, and Queens. Highway crashes increase again (similar to winter but slightly less).

5. General Findings:
 Winter has the most crashes during transition periods, especially on highways, due to icy roads, reduced visibility, and early sunset.

 Summer has the fewest crashes during transition periods, likely due to better road conditions, longer daylight, and reduced traffic congestion in vacation months.

 Spring and Fall show intermediate trends, with Fall having slightly more transition crashes due to earlier sunsets.

 Nightlife areas see higher crash density in summer transition periods, suggesting a shift toward pedestrian/cyclist involvement.

 Highway crashes are more frequent in Winter and Fall, whereas Summer and Spring have more intersection/local street crashes.

### **Final Conclusion: The Impact of Day-to-Night Transition on Crashes in NYC Across Seasons**

Our analysis explored how the transition from daylight to nighttime impacts crash patterns in different seasons. We analyzed crash frequency, severity, weather conditions, borough-wise distribution, and temporal trends. Based on the data, several key insights emerged:

---

## **1. General Trends Across Seasons**
 **Crashes are highest during transition periods in Fall and Winter.**  
- Fall (5-7 PM) and Winter (4-6 PM) had the most transition-period crashes.
- This is likely due to **earlier sunsets, reduced visibility, and traffic congestion during evening rush hours**.

 **Spring and Summer see fewer transition crashes.**  
- **Spring (6-8 PM) and Summer (7-9 PM) have significantly fewer transition crashes.**
- **Extended daylight hours improve visibility and reduce risk.**

 **Winter has the highest nighttime crash proportion.**  
- The transition period in Winter **(4-6 PM)** contributes to a high percentage of crashes that continue into the night.
- **Early Darkness, icy roads, and increased use of highways contribute to crash risks.**

 **The evening rush hour (4-7 PM) is the most dangerous across all seasons.**  
- Transition crashes align with **rush hour periods**, indicating that **congestion and driver fatigue play major roles in accidents** with the Day light transition.

---

## **2. Crash Severity Insights**
 **Most crashes only involve property damage, but Winter & Fall crashes are more severe.**  
- **Winter and Fall** have a higher proportion of crashes resulting in **injuries and fatalities**.
- **Nighttime crashes tend to be more severe** than daytime crashes.

 **Winter transition crashes are disproportionately severe.**  
- **More crashes involve injuries and fatalities in Winterâ€™s 4-6 PM period compared to other seasons**.
- **Icy roads, early darkness, and colder temperatures impact driving conditions**.

---

## **3. Borough-Wise Observations**
 **Brooklyn and Queens experience the highest number of crashes.**  
- **Brooklyn sees the most crashes overall**, both before and after sunset.
- **Queens follows closely behind**, particularly in high-speed zones and intersections.

 **The Bronx has a higher proportion of nighttime crashes.**  
- Poor lighting in certain areas, high-speed roads, and infrastructure contribute to risk.

 **Staten Island has the lowest crash numbers overall.**  
- because of Less traffic.

---

## **4. Heatmap Insights: Crash Distribution Across Seasons**
 **Winter and Fall transition crashes are concentrated on highways and high-speed roads.**  
- Major roads like **Cross Bronx Expressway, FDR Drive, Grand Central Parkway, and BQE** showed higher crash densities.
- Suggests that **highway speeds, early darkness, and icy/slippery conditions** increase risk.

 **Summer transition crashes are more localized in nightlife and pedestrian-heavy areas.**  
- Crashes in **Times Square, Williamsburg, Lower East Side, and Astoria** suggest **higher pedestrian and cyclist involvement**.

 **Spring and Summer transition crashes shift toward local streets rather than highways.**  
- Intersections and pedestrian-heavy zones become **hotspots for accidents**.

 **Transition-period crashes increase near schools and transit hubs in Fall.**  
- Likely due to **student and commuter movement in the late afternoon/evening hours**.

---

## **6. Time-Series Analysis of Crashes Over the Years**


 **Winter and Fall transition crashes have remained consistently high over the years.**  
- Suggests that **seasonal and environmental factors play a critical role in transition-period crashes**.

---

## **Final Summary: The Key Takeaways**
1. **Winter and Fall transition periods (4-6 PM and 5-7 PM) are the most dangerous times for crashes across all seasons.**  
2. **Nighttime crashes, while fewer in number, tend to be more severe and fatal across all seasons.**  
3. **Brooklyn and Queens experience the highest number of transition-period crashes, while the Bronx has a higher nighttime crash ratio.**  
4. **Winter crashes are the most severe due to snow, ice, and poor visibility, while Summer sees the least transition crashes.**  
5. **Transition crashes in Fall are heavily influenced by early sunsets, wet roads, and pedestrian traffic.**  

---

## **Future Recommendations Based on Findings**
- **Improve lighting infrastructure in high-risk areas** (especially in the Bronx and Queens).  
- **Increase road safety awareness during Fall and Winter transition periods** when crash risks are highest.  
- **Enhance winter road maintenance and de-icing efforts, particularly on highways** where crashes are more frequent.  
- **Adjust traffic enforcement during evening rush hours in Fall and Winter** to reduce high-risk transition crashes.  
- **Implement pedestrian safety measures in nightlife districts, school zones, and transit hubs, particularly in Fall and Summer.**

##<font color='crimson'>**Milestone #6 - Virtual Poster Board Creation: Data Storytelling**</font>

GOAL: The main goal of this milestone is to create a one page, virtual poster board to portray your research findings and recommendations! Your poster may be shared with the Department of Transportation and Federal Highway Authority.

Within your poster, summarize your research question, your reasoning for selecting your data visualization or model choices, and key insights from your data analysis. You may also wish to include your outstanding research questions that could not be answered by the dataset and why.

**Be sure to answer the following on your virtual poster board:** Based on your research insights, what recommendations would you share with the Department of Transportation and Federal Highway Authority to make roads safer for vulnerable road users? Why?

**Additionally, be sure to cite all relevant sources that you referred to throughout this project on your poster board (MLA or APA citation preferred). List acknowlegdments if you received any support from mentors, professors, professionals, etc. throughout your journey.**

Please use the following resources to get started!


*   [Virtual Poster Board Template](https://nebigdatahub.org/wp-content/uploads/2024/01/Copy-of-dsi-poster.ppt-48-Ã—-36-in.pdf) - Your one-page, virtual poster may be created in PowerPoint, Google Slides, Canva, etc. Choose what you are most comfortable with!
* [ Data Storytelling: How to Effectively Tell a Story with Data](https://online.hbs.edu/blog/post/data-storytelling)

* [  Consider how your visualization(s) might appear to people with varying abilities ](https://chartability.fizz.studio/)
*  [Understand your audience for an optimal presentation](https://hbr.org/2013/04/how-to-tell-a-story-with-data)


Once completed, please use the [following TDSP Submission Form](https://docs.google.com/forms/d/e/1FAIpQLSeX1OSHj58EQs4ypFEPB_SH3OpWZeo67yU0WWOPVSqYtDrpWg/viewform) to share your Google Colab Notebook and your one-page, virtual project poster with the NSDC HQ Team.

---
---

## ðŸš—<font color='crimson'> **Thank you for completing the project!**</font> ðŸš—

We are one step closer to making roads safer for all. [Please submit all materials to the NSDC HQ team](https://docs.google.com/forms/d/e/1FAIpQLSeX1OSHj58EQs4ypFEPB_SH3OpWZeo67yU0WWOPVSqYtDrpWg/viewform) in order to receive a certificate of completion. Do reach out to us if you have any questions or concerns. We are here to help you learn and grow.
"""